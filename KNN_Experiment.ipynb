{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN_Experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "6JpBeZ5CF1oM",
        "gNkaETDts87r",
        "9CGvoMkuHEY1",
        "Pkw2LAfLOc1g",
        "sa52b1XnN3Qp"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananda1996ai/ML-Solutions-for-Donors-Choose-Acceptance-Prediction/blob/master/KNN_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAzddpf0F2Wm",
        "colab_type": "text"
      },
      "source": [
        "# K-NN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etNpzy7rCyl2",
        "colab_type": "text"
      },
      "source": [
        "<p>\n",
        "DonorsChoose.org receives hundreds of thousands of project proposals each year for classroom projects in need of funding. Right now, a large number of volunteers is needed to manually screen each submission before it's approved to be posted on the DonorsChoose.org website.\n",
        "</p>\n",
        "<p>\n",
        "    Next year, DonorsChoose.org expects to receive close to 500,000 project proposals. As a result, there are three main problems they need to solve:\n",
        "<ul>\n",
        "<li>\n",
        "    How to scale current manual processes and resources to screen 500,000 projects so that they can be posted as quickly and as efficiently as possible</li>\n",
        "    <li>How to increase the consistency of project vetting across different volunteers to improve the experience for teachers</li>\n",
        "    <li>How to focus volunteer time on the applications that need the most assistance</li>\n",
        "    </ul>\n",
        "</p>    \n",
        "<p>\n",
        "The goal of the competition is to predict whether or not a DonorsChoose.org project proposal submitted by a teacher will be approved, using the text of project descriptions as well as additional metadata about the project, teacher, and school. DonorsChoose.org can then use this information to identify projects most likely to need further review before approval.\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO2Kg7TgCyl4",
        "colab_type": "text"
      },
      "source": [
        "## About the DonorsChoose Data Set\n",
        "\n",
        "The `train.csv` data set provided by DonorsChoose contains the following features:\n",
        "\n",
        "Feature | Description \n",
        "----------|---------------\n",
        "**`project_id`** | A unique identifier for the proposed project. **Example:** `p036502`   \n",
        "**`project_title`**    | Title of the project. **Examples:**<br><ul><li><code>Art Will Make You Happy!</code></li><li><code>First Grade Fun</code></li></ul> \n",
        "**`project_grade_category`** | Grade level of students for which the project is targeted. One of the following enumerated values: <br/><ul><li><code>Grades PreK-2</code></li><li><code>Grades 3-5</code></li><li><code>Grades 6-8</code></li><li><code>Grades 9-12</code></li></ul>  \n",
        " **`project_subject_categories`** | One or more (comma-separated) subject categories for the project from the following enumerated list of values:  <br/><ul><li><code>Applied Learning</code></li><li><code>Care &amp; Hunger</code></li><li><code>Health &amp; Sports</code></li><li><code>History &amp; Civics</code></li><li><code>Literacy &amp; Language</code></li><li><code>Math &amp; Science</code></li><li><code>Music &amp; The Arts</code></li><li><code>Special Needs</code></li><li><code>Warmth</code></li></ul><br/> **Examples:** <br/><ul><li><code>Music &amp; The Arts</code></li><li><code>Literacy &amp; Language, Math &amp; Science</code></li>  \n",
        "  **`school_state`** | State where school is located ([Two-letter U.S. postal code](https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations#Postal_codes)). **Example:** `WY`\n",
        "**`project_subject_subcategories`** | One or more (comma-separated) subject subcategories for the project. **Examples:** <br/><ul><li><code>Literacy</code></li><li><code>Literature &amp; Writing, Social Sciences</code></li></ul> \n",
        "**`project_resource_summary`** | An explanation of the resources needed for the project. **Example:** <br/><ul><li><code>My students need hands on literacy materials to manage sensory needs!</code</li></ul> \n",
        "**`project_essay_1`**    | First application essay<sup>*</sup>  \n",
        "**`project_essay_2`**    | Second application essay<sup>*</sup> \n",
        "**`project_essay_3`**    | Third application essay<sup>*</sup> \n",
        "**`project_essay_4`**    | Fourth application essay<sup>*</sup> \n",
        "**`project_submitted_datetime`** | Datetime when project application was submitted. **Example:** `2016-04-28 12:43:56.245`   \n",
        "**`teacher_id`** | A unique identifier for the teacher of the proposed project. **Example:** `bdf8baa8fedef6bfeec7ae4ff1c15c56`  \n",
        "**`teacher_prefix`** | Teacher's title. One of the following enumerated values: <br/><ul><li><code>nan</code></li><li><code>Dr.</code></li><li><code>Mr.</code></li><li><code>Mrs.</code></li><li><code>Ms.</code></li><li><code>Teacher.</code></li></ul>  \n",
        "**`teacher_number_of_previously_posted_projects`** | Number of project applications previously submitted by the same teacher. **Example:** `2` \n",
        "\n",
        "<sup>*</sup> See the section <b>Notes on the Essay Data</b> for more details about these features.\n",
        "\n",
        "Additionally, the `resources.csv` data set provides more data about the resources required for each project. Each line in this file represents a resource required by a project:\n",
        "\n",
        "Feature | Description \n",
        "----------|---------------\n",
        "**`id`** | A `project_id` value from the `train.csv` file.  **Example:** `p036502`   \n",
        "**`description`** | Desciption of the resource. **Example:** `Tenor Saxophone Reeds, Box of 25`   \n",
        "**`quantity`** | Quantity of the resource required. **Example:** `3`   \n",
        "**`price`** | Price of the resource required. **Example:** `9.95`   \n",
        "\n",
        "**Note:** Many projects require multiple resources. The `id` value corresponds to a `project_id` in train.csv, so you use it as a key to retrieve all resources needed for a project:\n",
        "\n",
        "The data set contains the following label (the value you will attempt to predict):\n",
        "\n",
        "Label | Description\n",
        "----------|---------------\n",
        "`project_is_approved` | A binary flag indicating whether DonorsChoose approved the project. A value of `0` indicates the project was not approved, and a value of `1` indicates the project was approved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBGA_YStCyl6",
        "colab_type": "text"
      },
      "source": [
        "### Notes on the Essay Data\n",
        "\n",
        "<ul>\n",
        "Prior to May 17, 2016, the prompts for the essays were as follows:\n",
        "<li>__project_essay_1:__ \"Introduce us to your classroom\"</li>\n",
        "<li>__project_essay_2:__ \"Tell us more about your students\"</li>\n",
        "<li>__project_essay_3:__ \"Describe how your students will use the materials you're requesting\"</li>\n",
        "<li>__project_essay_3:__ \"Close by sharing why your project will make a difference\"</li>\n",
        "</ul>\n",
        "\n",
        "\n",
        "<ul>\n",
        "Starting on May 17, 2016, the number of essays was reduced from 4 to 2, and the prompts for the first 2 essays were changed to the following:<br>\n",
        "<li>__project_essay_1:__ \"Describe your students: What makes your students special? Specific details about their background, your neighborhood, and your school are all helpful.\"</li>\n",
        "<li>__project_essay_2:__ \"About your project: How will these materials make a difference in your students' learning and improve their school lives?\"</li>\n",
        "<br>For all projects with project_submitted_datetime of 2016-05-17 and later, the values of project_essay_3 and project_essay_4 will be NaN.\n",
        "</ul>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EctBRI5OFyWq",
        "colab_type": "code",
        "outputId": "355156d7-735c-48b5-c140-82f7fd756579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "#from plotly import plotly\n",
        "#import plotly.offline as offline\n",
        "#import plotly.graph_objs as go\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzfJt0fkotl_",
        "colab_type": "code",
        "outputId": "da8af782-4625-473f-9eb5-e853367b3235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JpBeZ5CF1oM",
        "colab_type": "text"
      },
      "source": [
        "## 1. Getting Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49lorjooGFM-",
        "colab_type": "text"
      },
      "source": [
        "### 1.1 Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1af5E2-b1HyH",
        "colab_type": "code",
        "outputId": "bf5d9990-f312-41bf-8c27-c0e43fff1979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "project_data = pd.read_csv(\"/content/drive/My Drive/Assignment_2 drive dwnld/train_data.csv\")\n",
        "resource_data = pd.read_csv(\"/content/drive/My Drive/Assignment_2 drive dwnld/resources.csv\")\n",
        "\n",
        "price_data = resource_data.groupby('id').agg({'price':'sum', 'quantity':'sum'}).reset_index()\n",
        "dataset = pd.merge(project_data, price_data, on='id', how='left')\n",
        "\n",
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109248, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWMgrrwTVCRW",
        "colab_type": "code",
        "outputId": "110de0f9-1c0b-4672-8122-9ce58c140e9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>teacher_id</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>school_state</th>\n",
              "      <th>project_submitted_datetime</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>project_subject_categories</th>\n",
              "      <th>project_subject_subcategories</th>\n",
              "      <th>project_title</th>\n",
              "      <th>project_essay_1</th>\n",
              "      <th>project_essay_2</th>\n",
              "      <th>project_essay_3</th>\n",
              "      <th>project_essay_4</th>\n",
              "      <th>project_resource_summary</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>160221</td>\n",
              "      <td>p253737</td>\n",
              "      <td>c90749f5d961ff158d4b4d1e7dc665fc</td>\n",
              "      <td>Mrs.</td>\n",
              "      <td>IN</td>\n",
              "      <td>2016-12-05 13:43:57</td>\n",
              "      <td>Grades PreK-2</td>\n",
              "      <td>Literacy &amp; Language</td>\n",
              "      <td>ESL, Literacy</td>\n",
              "      <td>Educational Support for English Learners at Home</td>\n",
              "      <td>My students are English learners that are work...</td>\n",
              "      <td>\\\"The limits of your language are the limits o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My students need opportunities to practice beg...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>154.6</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>140945</td>\n",
              "      <td>p258326</td>\n",
              "      <td>897464ce9ddc600bced1151f324dd63a</td>\n",
              "      <td>Mr.</td>\n",
              "      <td>FL</td>\n",
              "      <td>2016-10-25 09:22:10</td>\n",
              "      <td>Grades 6-8</td>\n",
              "      <td>History &amp; Civics, Health &amp; Sports</td>\n",
              "      <td>Civics &amp; Government, Team Sports</td>\n",
              "      <td>Wanted: Projector for Hungry Learners</td>\n",
              "      <td>Our students arrive to our school eager to lea...</td>\n",
              "      <td>The projector we need for our school is very c...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My students need a projector to help with view...</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>299.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0       id  ...  price quantity\n",
              "0      160221  p253737  ...  154.6       23\n",
              "1      140945  p258326  ...  299.0        1\n",
              "\n",
              "[2 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhVavBN_X_Qd",
        "colab_type": "text"
      },
      "source": [
        "### 1.2 Dataset Cleaning and pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lhFHImI746N",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.1 Dropping irrelevant data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boa4YEYLcI08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For the purposes of classification, the columns 'unnamed', 'id', and 'teacher_id' must be dropped as they are unique for each record and will cause over-fitting.\n",
        "#For classification, we'll consider only numerical features, categorical features, and text festures. Thus we also drop date-time information.\n",
        "\n",
        "dataset.drop(['Unnamed: 0', 'id', 'teacher_id', 'project_submitted_datetime'], axis=1, inplace=True)\n",
        "\n",
        "#As KNN is not suitable for large datasets, we downsample to 50K points from the original dataset.\n",
        "\n",
        "dataset = resample(dataset, n_samples=50000, replace=False, stratify=dataset['project_is_approved'].values)\n",
        "dataset = dataset.reset_index()\n",
        "dataset.drop(['index'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTbUoT__pynG",
        "colab_type": "code",
        "outputId": "9cb36f7b-d3ce-4335-8103-d21d31da4c50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(dataset.shape)\n",
        "dataset.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 15)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>school_state</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>project_subject_categories</th>\n",
              "      <th>project_subject_subcategories</th>\n",
              "      <th>project_title</th>\n",
              "      <th>project_essay_1</th>\n",
              "      <th>project_essay_2</th>\n",
              "      <th>project_essay_3</th>\n",
              "      <th>project_essay_4</th>\n",
              "      <th>project_resource_summary</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mrs.</td>\n",
              "      <td>TX</td>\n",
              "      <td>Grades PreK-2</td>\n",
              "      <td>Health &amp; Sports, Literacy &amp; Language</td>\n",
              "      <td>Health &amp; Wellness, Literature &amp; Writing</td>\n",
              "      <td>Wiggle While You Learn: Flexible Seating Optio...</td>\n",
              "      <td>My second graders have learned to work coopera...</td>\n",
              "      <td>In today's classroom, we as teachers cater to ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My students need flexible seating options that...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>291.30</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mrs.</td>\n",
              "      <td>LA</td>\n",
              "      <td>Grades PreK-2</td>\n",
              "      <td>Literacy &amp; Language, Applied Learning</td>\n",
              "      <td>Literacy, Other</td>\n",
              "      <td>Autism Listens</td>\n",
              "      <td>are completely amazing, and teach me everyday!...</td>\n",
              "      <td>In an Autism classroom we model all day to the...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>My students need a Listening Center to help br...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>367.99</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  teacher_prefix school_state  ...   price quantity\n",
              "0           Mrs.           TX  ...  291.30       16\n",
              "1           Mrs.           LA  ...  367.99        4\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MIW-5A78AhZ",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.2 Text pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzLI_9oFmXDx",
        "colab_type": "code",
        "outputId": "192c7c16-6816-4a4a-d0e7-3565aee1ed7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# https://stackoverflow.com/a/47091490/4084039\n",
        "import re\n",
        "\n",
        "def decontracted(phrase):\n",
        "  # specific\n",
        "  phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
        "  phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "\n",
        "  # general\n",
        "  phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "  phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "  phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "  phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "  phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "  phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "  phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "  phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "  return phrase\n",
        "\n",
        "sw = set(stopwords.words('english')) #Using NLTK list of stopwords.\n",
        "\n",
        "#PRE-PROCESSING ON ESSAYS\n",
        "\n",
        "dataset[\"essay\"] = dataset[\"project_essay_1\"].map(str) + dataset[\"project_essay_2\"].map(str) + dataset[\"project_essay_3\"].map(str) + dataset[\"project_essay_4\"].map(str)\n",
        "\n",
        "dataset.drop(['project_essay_1', 'project_essay_2', 'project_essay_3', 'project_essay_4'], axis=1, inplace=True)\n",
        "\n",
        "preprocessed_essays = []\n",
        "for sentence in tqdm(dataset['essay'].values):\n",
        "  sent = decontracted(sentence)\n",
        "  sent = sent.replace('\\\\r', ' ')\n",
        "  sent = sent.replace('\\\\\"', ' ')\n",
        "  sent = sent.replace('\\\\n', ' ')\n",
        "  sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "  # https://gist.github.com/sebleier/554280\n",
        "  sent = ' '.join(w for w in sent.split() if w not in sw)\n",
        "  preprocessed_essays.append(sent.lower().strip())\n",
        "    \n",
        "dataset[\"essay\"] = preprocessed_essays  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:07<00:00, 7068.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUS4ia-qFUgP",
        "colab_type": "code",
        "outputId": "6b62b87c-b919-4e44-e7b9-b0ce6219f42f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#PRE-PROCESSING ON TITLES\n",
        "\n",
        "preprocessed_titles = []\n",
        "\n",
        "for sentence in tqdm(dataset['project_title'].values):\n",
        "  sent = decontracted(sentence)\n",
        "  sent = sent.replace('\\\\r', ' ')\n",
        "  sent = sent.replace('\\\\\"', ' ')\n",
        "  sent = sent.replace('\\\\n', ' ')\n",
        "  sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "  # https://gist.github.com/sebleier/554280\n",
        "  sent = ' '.join(w for w in sent.split() if w not in sw)\n",
        "  preprocessed_titles.append(sent.lower().strip())\n",
        "  \n",
        "dataset[\"project_title\"] = preprocessed_titles"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:00<00:00, 74491.77it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBbU0UzNGOFm",
        "colab_type": "code",
        "outputId": "1ec1254b-2eb2-4537-a56f-5e2ee3cbc48a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#PRE_PROCESSING ON RESOURCE SUMMARY\n",
        "\n",
        "preprocessed_summary = []\n",
        "\n",
        "for sentence in tqdm(dataset['project_resource_summary'].values):\n",
        "  sent = decontracted(sentence)\n",
        "  sent = sent.replace('\\\\r', ' ')\n",
        "  sent = sent.replace('\\\\\"', ' ')\n",
        "  sent = sent.replace('\\\\n', ' ')\n",
        "  sent = re.sub('[^A-Za-z0-9]+', ' ', sent)\n",
        "  # https://gist.github.com/sebleier/554280\n",
        "  sent = ' '.join(w for w in sent.split() if w not in sw)\n",
        "  preprocessed_summary.append(sent.lower().strip())\n",
        "  \n",
        "dataset['project_resource_summary'] = preprocessed_summary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:01<00:00, 46552.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5-jzum9MbOr",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.3 Categorical data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUvtnwcdJZp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning TEACHER_PREFIXES\n",
        "\n",
        "dataset['teacher_prefix'].fillna('NA', inplace=True)\n",
        "dataset['teacher_prefix'] = dataset['teacher_prefix'].apply(lambda s: s.replace('.', ''))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVCF-G-MOa81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cleaning PROJECT_GRADE_CATEGORIES\n",
        "\n",
        "dataset['project_grade_category'] = dataset['project_grade_category'].apply(lambda s: re.sub(r'[\\s\\-]+', '_', s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imjoWyM0RFjr",
        "colab_type": "code",
        "outputId": "d662c1ec-03ba-46d9-e333-449aad26969a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Cleaning PROJECT_SUBJECT_CATEGORIES\n",
        "\n",
        "cat_list = []\n",
        "for category in tqdm(dataset['project_subject_categories'].values):\n",
        "  temp = \"\"\n",
        "  for j in category.split(','):\n",
        "    \n",
        "      if 'The' in j.split(): \n",
        "          j=j.replace('The','')\n",
        "          \n",
        "      j = j.replace(' ','')\n",
        "      \n",
        "      temp+=j.strip()+\" \"\n",
        "      \n",
        "      temp = temp.replace('&','_')\n",
        "      \n",
        "  cat_list.append(temp.strip())\n",
        "  \n",
        "dataset['clean_categories'] = cat_list\n",
        "dataset.drop('project_subject_categories', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:00<00:00, 471488.37it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXtEKpTdTDhF",
        "colab_type": "code",
        "outputId": "37a72e51-bec8-4a45-8c2e-1775ec4062cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Cleaning PROJECT_SUBJECT_SUBCATEGORY\n",
        "\n",
        "subcat_list = []\n",
        "for subcategory in tqdm(dataset['project_subject_subcategories'].values):\n",
        "  temp = \"\"\n",
        "  for j in subcategory.split(','):\n",
        "    \n",
        "      if 'The' in j.split(): \n",
        "          j=j.replace('The','')\n",
        "          \n",
        "      j = j.replace(' ','')\n",
        "      \n",
        "      temp+=j.strip()+\" \"\n",
        "      \n",
        "      temp = temp.replace('&','_')\n",
        "      \n",
        "  subcat_list.append(temp.strip())\n",
        "  \n",
        "dataset['clean_subcategories'] = subcat_list\n",
        "dataset.drop('project_subject_subcategories', axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50000/50000 [00:00<00:00, 444291.16it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "942CC_5ETktp",
        "colab_type": "code",
        "outputId": "0028cc59-679e-42f8-9640-23cd6129ef96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>school_state</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>project_title</th>\n",
              "      <th>project_resource_summary</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "      <th>essay</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mrs</td>\n",
              "      <td>TX</td>\n",
              "      <td>Grades_PreK_2</td>\n",
              "      <td>wiggle while you learn flexible seating option...</td>\n",
              "      <td>my students need flexible seating options incl...</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>291.30</td>\n",
              "      <td>16</td>\n",
              "      <td>my second graders learned work cooperatively w...</td>\n",
              "      <td>Health_Sports Literacy_Language</td>\n",
              "      <td>Health_Wellness Literature_Writing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mrs</td>\n",
              "      <td>LA</td>\n",
              "      <td>Grades_PreK_2</td>\n",
              "      <td>autism listens</td>\n",
              "      <td>my students need listening center help broaden...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>367.99</td>\n",
              "      <td>4</td>\n",
              "      <td>completely amazing teach everyday they bravely...</td>\n",
              "      <td>Literacy_Language AppliedLearning</td>\n",
              "      <td>Literacy Other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ms</td>\n",
              "      <td>CA</td>\n",
              "      <td>Grades_6_8</td>\n",
              "      <td>keep me active</td>\n",
              "      <td>my students need sports equipment keep active ...</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>78.97</td>\n",
              "      <td>16</td>\n",
              "      <td>our students come diverse backgrounds over 90 ...</td>\n",
              "      <td>Health_Sports</td>\n",
              "      <td>Gym_Fitness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  teacher_prefix  ...                 clean_subcategories\n",
              "0            Mrs  ...  Health_Wellness Literature_Writing\n",
              "1            Mrs  ...                      Literacy Other\n",
              "2             Ms  ...                         Gym_Fitness\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYt-HGw0Tnvv",
        "colab_type": "code",
        "outputId": "1bf9546e-95e6-4d6a-f7ad-e1d404f87138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmaj_lfFW3sE",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2.4 Cleaning numerical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhHn9goUW8vY",
        "colab_type": "code",
        "outputId": "fcce4e2e-4875-426c-f6f9-d574bbfd7ff2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Checking if any of the numerical features have missing values...\n",
        "isnan = []\n",
        "for f in ('teacher_number_of_previously_posted_projects', 'price', 'quantity'):\n",
        "  isnan.append(dataset[f].isna().values.any())\n",
        "  \n",
        "any(isnan)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K-K8Wn0Zfd8",
        "colab_type": "text"
      },
      "source": [
        "Thus we do not have any missing values in numerical data. No cleaning required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIs9wvzLGKkK",
        "colab_type": "text"
      },
      "source": [
        "### 1.3 Divide data into Train, Val, Test using Stratified Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYYGJBblN2QC",
        "colab_type": "code",
        "outputId": "0553d058-ba85-485a-f857-073a6bedc64e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df = resample(dataset, n_samples=35000, replace=False, stratify=dataset['project_is_approved'].values)\n",
        "\n",
        "train_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXnGA18rSxFd",
        "colab_type": "code",
        "outputId": "f3b3e746-e073-4833-b5e8-bcdfc26e0da5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset_idx = pd.Index(dataset.index.values)\n",
        "train_idx = pd.Index(train_df.index.values)\n",
        "rem_idx = dataset_idx.difference(train_idx)\n",
        "rem_df = dataset.iloc[rem_idx]\n",
        "\n",
        "val_df = resample(rem_df, n_samples=5000, replace=False, stratify=rem_df['project_is_approved'].values)\n",
        "\n",
        "val_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5767aHYgV3N",
        "colab_type": "code",
        "outputId": "77420d1a-2a10-4ac5-d373-e128523c9b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "val_idx = pd.Index(val_df.index.values)\n",
        "test_idx = rem_idx.difference(val_idx)\n",
        "\n",
        "test_df = dataset.iloc[test_idx]\n",
        "\n",
        "test_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTK2rfE0GaRr",
        "colab_type": "text"
      },
      "source": [
        "### 1.4 Balance the Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcSzOc2QyhP4",
        "colab_type": "code",
        "outputId": "46680c4d-1413-4cb1-cbca-d35b9808763b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df['project_is_approved'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    29700\n",
              "0     5300\n",
              "Name: project_is_approved, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqV1iiIYnjA7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now we balance the dataset by upsampling the minority class points. \n",
        "\n",
        "minor_data = train_df[train_df['project_is_approved']==0]\n",
        "major_data = train_df[train_df['project_is_approved']==1]\n",
        "\n",
        "minor_data_upsampled = resample(minor_data, n_samples=29700)   #Equal to the size of major class\n",
        "\n",
        "balanced_train_df = pd.concat([major_data, minor_data_upsampled])\n",
        "\n",
        "#Now, to set the dataset to a mangeable size, we sample 100K points from the balanced train data stratified on class labels.\n",
        "train_df = resample(balanced_train_df, n_samples=35000, replace=False, stratify=balanced_train_df['project_is_approved'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHLEQVTXlvaa",
        "colab_type": "code",
        "outputId": "1f56ead4-411f-4831-dbb8-98167f2fd0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Now the train dataset is exactly balanced\n",
        "\n",
        "train_df['project_is_approved'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    17500\n",
              "0    17500\n",
              "Name: project_is_approved, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq2LR_uTp7aM",
        "colab_type": "code",
        "outputId": "e830b04a-838d-4e4c-93f9-26472fc61bab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>school_state</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>project_title</th>\n",
              "      <th>project_resource_summary</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>price</th>\n",
              "      <th>quantity</th>\n",
              "      <th>essay</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22218</th>\n",
              "      <td>Ms</td>\n",
              "      <td>SC</td>\n",
              "      <td>Grades_PreK_2</td>\n",
              "      <td>steaming stem nonfiction book</td>\n",
              "      <td>my students need colored pencils markers blank...</td>\n",
              "      <td>88</td>\n",
              "      <td>0</td>\n",
              "      <td>373.17</td>\n",
              "      <td>36</td>\n",
              "      <td>let build wow awesome wish i could make book m...</td>\n",
              "      <td>Math_Science</td>\n",
              "      <td>EnvironmentalScience</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16863</th>\n",
              "      <td>Mr</td>\n",
              "      <td>CO</td>\n",
              "      <td>Grades_3_5</td>\n",
              "      <td>keep the pace create some space</td>\n",
              "      <td>my students need plastic colored magazine hold...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>62.98</td>\n",
              "      <td>8</td>\n",
              "      <td>this second year 3rd grade teacher i going hon...</td>\n",
              "      <td>AppliedLearning</td>\n",
              "      <td>Other</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      teacher_prefix school_state  ... clean_categories   clean_subcategories\n",
              "22218             Ms           SC  ...     Math_Science  EnvironmentalScience\n",
              "16863             Mr           CO  ...  AppliedLearning                 Other\n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNkaETDts87r",
        "colab_type": "text"
      },
      "source": [
        "## Features for classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIutN6mctJx4",
        "colab_type": "text"
      },
      "source": [
        "For classification, we are going to consider\n",
        "\n",
        "   - school_state : categorical data (One-hot encoded)\n",
        "   - clean_categories : categorical data (One-hot encoded)\n",
        "   - clean_subcategories : categorical data (One-hot encoded)\n",
        "   - project_grade_category : categorical data (One-hot encoded)\n",
        "   - teacher_prefix : categorical data (One-hot encoded)\n",
        "\n",
        "   - **project_title : text data (BOW, TFIDF, AVG_W2V, TFIDF_W2V)**\n",
        "   - **essay : text data (BOW, TFIDF, AVG_W2V, TFIDF_W2V)**\n",
        "   - project_resource_summary: text data (optional) (TFIDF)\n",
        "\n",
        "   - quantity : numerical (optional) (Vectorized)\n",
        "   - teacher_number_of_previously_posted_projects : numerical (Vectorized)\n",
        "   - price : numerical (Vectorized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWvXZF_aGkR8",
        "colab_type": "text"
      },
      "source": [
        "## 2. Encoding Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CGvoMkuHEY1",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 Create all encoders using Train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2fsN-v1uM85",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1.1 Vectorizers for categorical data (One-hot encoders)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz-KPrtxZyt-",
        "colab_type": "code",
        "outputId": "36de8669-8afb-4b69-e29a-ca4878d85646",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Vectorizer for CLEAN_CATEGORIES\n",
        "\n",
        "cat_list = set()\n",
        "\n",
        "for categories in train_df['clean_categories'].values:\n",
        "  for word in categories.split():\n",
        "    cat_list.add(word)\n",
        "\n",
        "cat_vectorizer = CountVectorizer(vocabulary=list(cat_list), lowercase=False, binary=True)\n",
        "cat_vectorizer.fit(train_df['clean_categories'].values)\n",
        "print(cat_vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AppliedLearning', 'Math_Science', 'History_Civics', 'Care_Hunger', 'Music_Arts', 'Health_Sports', 'SpecialNeeds', 'Warmth', 'Literacy_Language']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vR4giiQ4Eda",
        "colab_type": "code",
        "outputId": "e58dfa7e-7dac-49cf-a85a-f7b250c5ef9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Vectorizer for CLEAN_SUBCATEGORIES\n",
        "\n",
        "subcat_list = set()\n",
        "\n",
        "for subcategories in train_df['clean_subcategories'].values:\n",
        "  for word in subcategories.split():\n",
        "    subcat_list.add(word)\n",
        "\n",
        "subcat_vectorizer = CountVectorizer(vocabulary=list(subcat_list), lowercase=False, binary=True)\n",
        "subcat_vectorizer.fit(train_df['clean_subcategories'].values)\n",
        "print(subcat_vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['EarlyDevelopment', 'PerformingArts', 'Extracurricular', 'SocialSciences', 'AppliedSciences', 'TeamSports', 'ESL', 'CharacterEducation', 'Literature_Writing', 'Health_LifeScience', 'History_Geography', 'College_CareerPrep', 'VisualArts', 'Gym_Fitness', 'Civics_Government', 'EnvironmentalScience', 'Mathematics', 'FinancialLiteracy', 'ParentInvolvement', 'Music', 'CommunityService', 'Literacy', 'ForeignLanguages', 'Health_Wellness', 'Other', 'Economics', 'NutritionEducation', 'Care_Hunger', 'SpecialNeeds', 'Warmth']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkd9QIQk458V",
        "colab_type": "code",
        "outputId": "7dd968d4-7cd7-4fd4-ef05-92cc98f20a3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Vectorizer for PROJECT_GRADE_CATEGORIES\n",
        "\n",
        "grades_list = set(train_df['project_grade_category'].values)\n",
        "\n",
        "grade_vectorizer = CountVectorizer(vocabulary=list(grades_list), lowercase=False, binary=True)\n",
        "grade_vectorizer.fit(train_df['project_grade_category'].values)\n",
        "print(grade_vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Grades_3_5', 'Grades_9_12', 'Grades_PreK_2', 'Grades_6_8']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6tfULFG5l80",
        "colab_type": "code",
        "outputId": "61aa775a-5c85-4fdb-e34b-cab90b86c9fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Vectorizer for SCHOOL_STATE\n",
        "\n",
        "state_list = set(train_df['school_state'].values)\n",
        "\n",
        "state_vectorizer = CountVectorizer(vocabulary=list(state_list), lowercase=False, binary=True)\n",
        "state_vectorizer.fit(train_df['school_state'].values)\n",
        "print(state_vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ID', 'OK', 'OR', 'SC', 'IN', 'KY', 'AZ', 'AR', 'DE', 'WY', 'TX', 'MD', 'MS', 'AL', 'HI', 'CA', 'TN', 'MT', 'GA', 'NC', 'DC', 'CT', 'FL', 'SD', 'UT', 'NY', 'WI', 'MN', 'WV', 'NM', 'NH', 'MI', 'IA', 'KS', 'MO', 'ME', 'RI', 'NE', 'CO', 'AK', 'PA', 'ND', 'MA', 'OH', 'LA', 'WA', 'NJ', 'VA', 'IL', 'VT', 'NV']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csh465Tw6YsN",
        "colab_type": "code",
        "outputId": "0f7d93da-bb0d-49c7-ffc4-6b86395ae09d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Vectorizer for TEACHER_PREFIX\n",
        "\n",
        "prefix_list = set(train_df['teacher_prefix'].values)\n",
        "\n",
        "pf_vectorizer = CountVectorizer(vocabulary=list(prefix_list), lowercase=False, binary=True)\n",
        "pf_vectorizer.fit(train_df['teacher_prefix'].values)\n",
        "print(pf_vectorizer.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Teacher', 'NA', 'Dr', 'Ms', 'Mr', 'Mrs']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZaFrce9a_2a",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1.2 Vectorizers for text data (BOW, TFIDF, AVG_W2V, TFIDF_W2V)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuJJ8HJ5bJcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BOW vectorizer for PROJECT_TITLE\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=5, max_features=200)\n",
        "bow_vectrzr_title = vectorizer.fit(train_df['project_title'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZFevkYg0qYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#BOW vectorizer for ESSAY\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=5, max_features=1000)\n",
        "bow_vectrzr_essay = vectorizer.fit(train_df['essay'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiTpHJu1wUhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TFIDF vectorizer for PROJECT_TITLE\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=5, max_features=200)\n",
        "tfidf_vectrzr_title = vectorizer.fit(train_df['project_title'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4NQzeOl007M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TFIDF vectorizer for ESSAY\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=5, max_features=1000)\n",
        "tfidf_vectrzr_essay = vectorizer.fit(train_df['essay'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkCS2Ke3wtF_",
        "colab_type": "code",
        "outputId": "b4a1e9bc-1800-4953-db36-ccc1c9d40296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# W2V using pre-trained model (Glove model)\n",
        "\n",
        "def loadGloveModel(gloveFile):\n",
        "  print (\"Loading Glove Model\")\n",
        "  f = open(gloveFile,'r', encoding=\"utf8\")\n",
        "  model = {}\n",
        "  for line in tqdm(f):\n",
        "      splitLine = line.split()\n",
        "      word = splitLine[0]\n",
        "      embedding = np.array([float(val) for val in splitLine[1:]])\n",
        "      model[word] = embedding\n",
        "  print (\"Done.\",len(model),\" words loaded!\")\n",
        "  return model\n",
        "\n",
        "g_model = loadGloveModel('/content/drive/My Drive/gloVe vectors/glove.42B.300d.txt')\n",
        "\n",
        "words = []\n",
        "\n",
        "for i in train_df['project_title'].values:\n",
        "  words.extend(i.split(' '))\n",
        "    \n",
        "for i in train_df['essay'].values:\n",
        "  words.extend(i.split(' '))\n",
        "\n",
        "words = set(words)\n",
        "\n",
        "words_corpus = {}\n",
        "words_glove = set(g_model.keys())\n",
        "for i in words:\n",
        "    if i in words_glove:\n",
        "        words_corpus[i] = g_model[i]\n",
        "\n",
        "with open('glove_vectors', 'wb') as f:\n",
        "    pickle.dump(words_corpus, f)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading Glove Model\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1917495it [03:27, 9225.69it/s] \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done. 1917495  words loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5jlRvCQC9ye",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title_dictionary = dict(zip(tfidf_vectrzr_title.get_feature_names(), list(tfidf_vectrzr_title.idf_)))\n",
        "tfidf_title_words = set(tfidf_vectrzr_title.get_feature_names())\n",
        "\n",
        "essay_dictionary = dict(zip(tfidf_vectrzr_essay.get_feature_names(), list(tfidf_vectrzr_essay.idf_)))\n",
        "tfidf_essay_words = set(tfidf_vectrzr_essay.get_feature_names())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bElk6AwcL1q9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For project_resource_summary (TFIDF)\n",
        "\n",
        "vectorizer = TfidfVectorizer(min_df=5)\n",
        "tfidf_vectrzr_summ = vectorizer.fit(train_df['project_resource_summary'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwThcXGZkpeQ",
        "colab_type": "text"
      },
      "source": [
        "#### 2.1.3 Vectorizers for numerical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TolCgwu5kzRq",
        "colab_type": "code",
        "outputId": "66421a72-5021-4ef1-c2a3-008a27c39367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#For PRICE\n",
        "\n",
        "price_scalar = StandardScaler()\n",
        "price_scalar.fit(train_df['price'].values.reshape(-1,1))\n",
        "\n",
        "\n",
        "#For QUANTITY\n",
        "\n",
        "quantity_scalar = StandardScaler()\n",
        "quantity_scalar.fit(train_df['quantity'].values.reshape(-1,1))\n",
        "\n",
        "\n",
        "#For TEACHER_NUMBER_OF_PREVIOUSLY_POSTED_PROJECTS\n",
        "\n",
        "ppost_scalar = StandardScaler()\n",
        "ppost_scalar.fit(train_df['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StandardScaler(copy=True, with_mean=True, with_std=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtVV9iJWHMwj",
        "colab_type": "text"
      },
      "source": [
        "### 2.2 Transform Train, Validation & Test data: Generate four training sets; Four val sets; Four Test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HearN_5n2E4P",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.1. Transforming categorical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o93BO9E4BPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_clean_categories = cat_vectorizer.transform(train_df['clean_categories'].values)\n",
        "val_df_clean_categories = cat_vectorizer.transform(val_df['clean_categories'].values)\n",
        "test_df_clean_categories = cat_vectorizer.transform(test_df['clean_categories'].values)\n",
        "\n",
        "train_df_clean_subcategories = subcat_vectorizer.transform(train_df['clean_subcategories'].values)\n",
        "val_df_clean_subcategories = subcat_vectorizer.transform(val_df['clean_subcategories'].values)\n",
        "test_df_clean_subcategories = subcat_vectorizer.transform(test_df['clean_subcategories'].values)\n",
        "\n",
        "train_df_project_grade_category = grade_vectorizer.transform(train_df['project_grade_category'].values)\n",
        "val_df_project_grade_category = grade_vectorizer.transform(val_df['project_grade_category'].values)\n",
        "test_df_project_grade_category = grade_vectorizer.transform(test_df['project_grade_category'].values)\n",
        "\n",
        "train_df_school_state = state_vectorizer.transform(train_df['school_state'].values)\n",
        "val_df_school_state = state_vectorizer.transform(val_df['school_state'].values)\n",
        "test_df_school_state = state_vectorizer.transform(test_df['school_state'].values)\n",
        "\n",
        "train_df_teacher_prefix = pf_vectorizer.transform(train_df['teacher_prefix'].values)\n",
        "val_df_teacher_prefix = pf_vectorizer.transform(val_df['teacher_prefix'].values)\n",
        "test_df_teacher_prefix = pf_vectorizer.transform(test_df['teacher_prefix'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93agJSeGj5xg",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.2 Transforming (vectorizing) numerical features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFhwoaAYkKX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_price = price_scalar.transform(train_df['price'].values.reshape(-1, 1))\n",
        "val_df_price = price_scalar.transform(val_df['price'].values.reshape(-1, 1))\n",
        "test_df_price = price_scalar.transform(test_df['price'].values.reshape(-1, 1))\n",
        "\n",
        "train_df_quantity = quantity_scalar.transform(train_df['quantity'].values.reshape(-1, 1))\n",
        "val_df_quantity = quantity_scalar.transform(val_df['quantity'].values.reshape(-1, 1))\n",
        "test_df_quantity = quantity_scalar.transform(test_df['quantity'].values.reshape(-1, 1))\n",
        "\n",
        "train_df_pposts = ppost_scalar.transform(train_df['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1))\n",
        "val_df_pposts = ppost_scalar.transform(val_df['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1))\n",
        "test_df_pposts = ppost_scalar.transform(test_df['teacher_number_of_previously_posted_projects'].values.reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "o1SnFAsanor7"
      },
      "source": [
        "#### 2.2.3 Transforming text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSmcm08DnsRC",
        "colab_type": "code",
        "outputId": "e5cd9182-7886-44f5-99c7-5fb6d956b466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#For PROJECT_TITLE\n",
        "\n",
        "#BOW\n",
        "title_train_bow = bow_vectrzr_title.transform(train_df['project_title'].values)\n",
        "title_val_bow = bow_vectrzr_title.transform(val_df['project_title'].values)\n",
        "title_test_bow = bow_vectrzr_title.transform(test_df['project_title'].values)\n",
        "\n",
        "#TFIDF\n",
        "title_train_tfidf = tfidf_vectrzr_title.transform(train_df['project_title'].values)\n",
        "title_val_tfidf = tfidf_vectrzr_title.transform(val_df['project_title'].values)\n",
        "title_test_tfidf = tfidf_vectrzr_title.transform(test_df['project_title'].values)\n",
        "\n",
        "#AVG_W2V\n",
        "title_train_aw2v = []\n",
        "title_val_aw2v = []\n",
        "title_test_aw2v = []\n",
        "\n",
        "with open('glove_vectors', 'rb') as f:\n",
        "  g_model = pickle.load(f)\n",
        "  glove_words =  set(g_model.keys())\n",
        "\n",
        "for sentence in tqdm(train_df['project_title'].values):\n",
        "  vector = np.zeros(300)\n",
        "  cnt_words =0; \n",
        "  for word in sentence.split(): \n",
        "    if word in glove_words:\n",
        "      vector += g_model[word]\n",
        "      cnt_words += 1\n",
        "  if cnt_words != 0:\n",
        "      vector /= cnt_words\n",
        "  title_train_aw2v.append(vector)\n",
        "  \n",
        "for sentence in tqdm(val_df['project_title'].values):\n",
        "  vector = np.zeros(300)\n",
        "  cnt_words =0; \n",
        "  for word in sentence.split(): \n",
        "    if word in glove_words:\n",
        "      vector += g_model[word]\n",
        "      cnt_words += 1\n",
        "  if cnt_words != 0:\n",
        "      vector /= cnt_words\n",
        "  title_val_aw2v.append(vector)\n",
        "  \n",
        "for sentence in tqdm(test_df['project_title'].values):\n",
        "  vector = np.zeros(300)\n",
        "  cnt_words =0; \n",
        "  for word in sentence.split(): \n",
        "    if word in glove_words:\n",
        "      vector += g_model[word]\n",
        "      cnt_words += 1\n",
        "  if cnt_words != 0:\n",
        "      vector /= cnt_words\n",
        "  title_test_aw2v.append(vector)\n",
        "  \n",
        "#TFIDF_W2V\n",
        "tfidf_w2v_train_title = [];\n",
        "tfidf_w2v_val_title = [];\n",
        "tfidf_w2v_test_title = [];\n",
        "\n",
        "for sentence in tqdm(train_df['project_title'].values):\n",
        "  vector = np.zeros(300) \n",
        "  tf_idf_weight =0; \n",
        "  for word in sentence.split():\n",
        "    if (word in glove_words) and (word in tfidf_title_words):\n",
        "      vec = g_model[word] \n",
        "            \n",
        "      tf_idf = title_dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
        "      vector += (vec * tf_idf)\n",
        "      tf_idf_weight += tf_idf\n",
        "  if tf_idf_weight != 0:\n",
        "    vector /= tf_idf_weight\n",
        "  tfidf_w2v_train_title.append(vector)\n",
        "\n",
        "for sentence in tqdm(val_df['project_title'].values):\n",
        "  vector = np.zeros(300) \n",
        "  tf_idf_weight =0; \n",
        "  for word in sentence.split():\n",
        "    if (word in glove_words) and (word in tfidf_title_words):\n",
        "      vec = g_model[word] \n",
        "            \n",
        "      tf_idf = title_dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
        "      vector += (vec * tf_idf)\n",
        "      tf_idf_weight += tf_idf\n",
        "  if tf_idf_weight != 0:\n",
        "    vector /= tf_idf_weight\n",
        "  tfidf_w2v_val_title.append(vector)\n",
        "  \n",
        "for sentence in tqdm(test_df['project_title'].values):\n",
        "  vector = np.zeros(300) \n",
        "  tf_idf_weight =0; \n",
        "  for word in sentence.split():\n",
        "    if (word in glove_words) and (word in tfidf_title_words):\n",
        "      vec = g_model[word] \n",
        "            \n",
        "      tf_idf = title_dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
        "      vector += (vec * tf_idf)\n",
        "      tf_idf_weight += tf_idf\n",
        "  if tf_idf_weight != 0:\n",
        "    vector /= tf_idf_weight\n",
        "  tfidf_w2v_test_title.append(vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35000/35000 [00:00<00:00, 71312.85it/s]\n",
            "100%|██████████| 5000/5000 [00:00<00:00, 70442.54it/s]\n",
            "100%|██████████| 10000/10000 [00:00<00:00, 68944.89it/s]\n",
            "100%|██████████| 35000/35000 [00:00<00:00, 55953.85it/s]\n",
            "100%|██████████| 5000/5000 [00:00<00:00, 55509.88it/s]\n",
            "100%|██████████| 10000/10000 [00:00<00:00, 55185.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPq8yY98wJin",
        "colab_type": "code",
        "outputId": "fd2dcb9f-c6c9-4832-8775-96c8099f18ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#For ESSAY\n",
        "\n",
        "#BOW\n",
        "essay_train_bow = bow_vectrzr_essay.transform(train_df['essay'].values)\n",
        "essay_val_bow = bow_vectrzr_essay.transform(val_df['essay'].values)\n",
        "essay_test_bow = bow_vectrzr_essay.transform(test_df['essay'].values)\n",
        "\n",
        "#TFIDF\n",
        "essay_train_tfidf = tfidf_vectrzr_essay.transform(train_df['essay'].values)\n",
        "essay_val_tfidf = tfidf_vectrzr_essay.transform(val_df['essay'].values)\n",
        "essay_test_tfidf = tfidf_vectrzr_essay.transform(test_df['essay'].values)\n",
        "\n",
        "#AVG_W2V\n",
        "essay_train_aw2v = []\n",
        "essay_val_aw2v = []\n",
        "essay_test_aw2v = []\n",
        "\n",
        "for sentence in tqdm(train_df['essay'].values):\n",
        "  vector = np.zeros(300)\n",
        "  cnt_words =0; \n",
        "  for word in sentence.split(): \n",
        "    if word in glove_words:\n",
        "      vector += g_model[word]\n",
        "      cnt_words += 1\n",
        "  if cnt_words != 0:\n",
        "      vector /= cnt_words\n",
        "  essay_train_aw2v.append(vector)\n",
        "  \n",
        "for sentence in tqdm(val_df['essay'].values):\n",
        "  vector = np.zeros(300)\n",
        "  cnt_words =0; \n",
        "  for word in sentence.split(): \n",
        "    if word in glove_words:\n",
        "      vector += g_model[word]\n",
        "      cnt_words += 1\n",
        "  if cnt_words != 0:\n",
        "      vector /= cnt_words\n",
        "  essay_val_aw2v.append(vector)\n",
        "  \n",
        "for sentence in tqdm(test_df['essay'].values):\n",
        "  vector = np.zeros(300)\n",
        "  cnt_words =0; \n",
        "  for word in sentence.split(): \n",
        "    if word in glove_words:\n",
        "      vector += g_model[word]\n",
        "      cnt_words += 1\n",
        "  if cnt_words != 0:\n",
        "      vector /= cnt_words\n",
        "  essay_test_aw2v.append(vector)\n",
        "  \n",
        "#TFIDF_W2V\n",
        "tfidf_w2v_train_essays = [];\n",
        "tfidf_w2v_val_essays = [];\n",
        "tfidf_w2v_test_essays = [];\n",
        "\n",
        "for sentence in tqdm(train_df['essay'].values):\n",
        "  vector = np.zeros(300) \n",
        "  tf_idf_weight =0; \n",
        "  for word in sentence.split():\n",
        "    if (word in glove_words) and (word in tfidf_essay_words):\n",
        "      vec = g_model[word] \n",
        "            \n",
        "      tf_idf = essay_dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
        "      vector += (vec * tf_idf)\n",
        "      tf_idf_weight += tf_idf\n",
        "  if tf_idf_weight != 0:\n",
        "    vector /= tf_idf_weight\n",
        "  tfidf_w2v_train_essays.append(vector)\n",
        "\n",
        "for sentence in tqdm(val_df['essay'].values):\n",
        "  vector = np.zeros(300) \n",
        "  tf_idf_weight =0; \n",
        "  for word in sentence.split():\n",
        "    if (word in glove_words) and (word in tfidf_essay_words):\n",
        "      vec = g_model[word] \n",
        "            \n",
        "      tf_idf = essay_dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
        "      vector += (vec * tf_idf)\n",
        "      tf_idf_weight += tf_idf\n",
        "  if tf_idf_weight != 0:\n",
        "    vector /= tf_idf_weight\n",
        "  tfidf_w2v_val_essays.append(vector)\n",
        "  \n",
        "for sentence in tqdm(test_df['essay'].values):\n",
        "  vector = np.zeros(300) \n",
        "  tf_idf_weight =0; \n",
        "  for word in sentence.split():\n",
        "    if (word in glove_words) and (word in tfidf_essay_words):\n",
        "      vec = g_model[word] \n",
        "            \n",
        "      tf_idf = essay_dictionary[word]*(sentence.count(word)/len(sentence.split()))\n",
        "      vector += (vec * tf_idf)\n",
        "      tf_idf_weight += tf_idf\n",
        "  if tf_idf_weight != 0:\n",
        "    vector /= tf_idf_weight\n",
        "  tfidf_w2v_test_essays.append(vector)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 35000/35000 [00:10<00:00, 3399.16it/s]\n",
            "100%|██████████| 5000/5000 [00:01<00:00, 3382.79it/s]\n",
            "100%|██████████| 10000/10000 [00:02<00:00, 3395.08it/s]\n",
            "100%|██████████| 35000/35000 [00:47<00:00, 731.43it/s]\n",
            "100%|██████████| 5000/5000 [00:07<00:00, 705.96it/s]\n",
            "100%|██████████| 10000/10000 [00:14<00:00, 712.44it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGb4erGbHyWE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TFIDF vectorization of project_resource_summary\n",
        "\n",
        "train_df_project_resource_summary = tfidf_vectrzr_summ.transform(train_df['project_resource_summary'].values)\n",
        "val_df_project_resource_summary = tfidf_vectrzr_summ.transform(val_df['project_resource_summary'].values)\n",
        "test_df_project_resource_summary = tfidf_vectrzr_summ.transform(test_df['project_resource_summary'].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y0JNPwzB61i",
        "colab_type": "text"
      },
      "source": [
        "#### 2.2.4 Generating the sets of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9IJbJM0CN5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SET_1: categorical, numerical features + project_title(BOW) + preprocessed_essay (BOW)\n",
        "train_set_1x = sparse.hstack((train_df_teacher_prefix, train_df_school_state, train_df_project_grade_category, train_df_clean_categories, train_df_clean_subcategories, train_df_price, train_df_quantity, train_df_pposts, train_df_project_resource_summary, title_train_bow, essay_train_bow))\n",
        "train_set_1y = train_df['project_is_approved'].to_numpy()\n",
        "\n",
        "val_set_1x = sparse.hstack((val_df_teacher_prefix, val_df_school_state, val_df_project_grade_category, val_df_clean_categories, val_df_clean_subcategories, val_df_price, val_df_quantity, val_df_pposts, val_df_project_resource_summary, title_val_bow, essay_val_bow))\n",
        "val_set_1y = val_df['project_is_approved'].to_numpy()\n",
        "\n",
        "test_set_1x = sparse.hstack((test_df_teacher_prefix, test_df_school_state, test_df_project_grade_category, test_df_clean_categories, test_df_clean_subcategories, test_df_price, test_df_quantity, test_df_pposts, test_df_project_resource_summary, title_test_bow, essay_test_bow))\n",
        "test_set_1y = test_df['project_is_approved'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhx-V_MLUCat",
        "colab_type": "code",
        "outputId": "9f3ba18b-25fb-4080-9e68-e81ce1ab4bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_set_1x.shape)\n",
        "print(val_set_1x.shape)\n",
        "print(test_set_1x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 6403)\n",
            "(5000, 6403)\n",
            "(10000, 6403)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUAgyVkpZR5I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SET_2: categorical, numerical features + project_title(TFIDF) + preprocessed_essay (TFIDF)\n",
        "train_set_2x = sparse.hstack((train_df_teacher_prefix, train_df_school_state, train_df_project_grade_category, train_df_clean_categories, train_df_clean_subcategories, train_df_price, train_df_quantity, train_df_pposts, train_df_project_resource_summary, title_train_tfidf, essay_train_tfidf))\n",
        "train_set_2y = train_df['project_is_approved'].to_numpy()\n",
        "\n",
        "val_set_2x = sparse.hstack((val_df_teacher_prefix, val_df_school_state, val_df_project_grade_category, val_df_clean_categories, val_df_clean_subcategories, val_df_price, val_df_quantity, val_df_pposts, val_df_project_resource_summary, title_val_tfidf, essay_val_tfidf))\n",
        "val_set_2y = val_df['project_is_approved'].to_numpy()\n",
        "\n",
        "test_set_2x = sparse.hstack((test_df_teacher_prefix, test_df_school_state, test_df_project_grade_category, test_df_clean_categories, test_df_clean_subcategories, test_df_price, test_df_quantity, test_df_pposts, test_df_project_resource_summary, title_test_tfidf, essay_test_tfidf))\n",
        "test_set_2y = test_df['project_is_approved'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5edd2b58-3d59-4939-fc74-d01e78fe6948",
        "id": "O3GMMoHaZ5QF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_set_2x.shape)\n",
        "print(val_set_2x.shape)\n",
        "print(test_set_2x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 6403)\n",
            "(5000, 6403)\n",
            "(10000, 6403)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyUft91zaEt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SET_3: categorical, numerical features + project_title(AVG_W2V) + preprocessed_essay (AVG_W2V)\n",
        "train_set_3x = sparse.hstack((train_df_teacher_prefix, train_df_school_state, train_df_project_grade_category, train_df_clean_categories, train_df_clean_subcategories, train_df_price, train_df_quantity, train_df_pposts, train_df_project_resource_summary, title_train_aw2v, essay_train_aw2v))\n",
        "train_set_3y = train_df['project_is_approved'].to_numpy()\n",
        "\n",
        "val_set_3x = sparse.hstack((val_df_teacher_prefix, val_df_school_state, val_df_project_grade_category, val_df_clean_categories, val_df_clean_subcategories, val_df_price, val_df_quantity, val_df_pposts, val_df_project_resource_summary, title_val_aw2v, essay_val_aw2v))\n",
        "val_set_3y = val_df['project_is_approved'].to_numpy()\n",
        "\n",
        "test_set_3x = sparse.hstack((test_df_teacher_prefix, test_df_school_state, test_df_project_grade_category, test_df_clean_categories, test_df_clean_subcategories, test_df_price, test_df_quantity, test_df_pposts, test_df_project_resource_summary, title_test_aw2v, essay_test_aw2v))\n",
        "test_set_3y = test_df['project_is_approved'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "fc977dd5-41eb-4751-f112-f35a969e2627",
        "id": "2G2SKYIna41Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_set_3x.shape)\n",
        "print(val_set_3x.shape)\n",
        "print(test_set_3x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 5803)\n",
            "(5000, 5803)\n",
            "(10000, 5803)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_y1PMO7ZbIf_",
        "colab": {}
      },
      "source": [
        "#SET_4: categorical, numerical features + project_title(TFIDF_W2V) + preprocessed_essay (TFIDF_W2V)\n",
        "train_set_4x = sparse.hstack((train_df_teacher_prefix, train_df_school_state, train_df_project_grade_category, train_df_clean_categories, train_df_clean_subcategories, train_df_price, train_df_quantity, train_df_pposts, train_df_project_resource_summary, tfidf_w2v_train_title, tfidf_w2v_train_essays))\n",
        "train_set_4y = train_df['project_is_approved'].to_numpy()\n",
        "\n",
        "val_set_4x = sparse.hstack((val_df_teacher_prefix, val_df_school_state, val_df_project_grade_category, val_df_clean_categories, val_df_clean_subcategories, val_df_price, val_df_quantity, val_df_pposts, val_df_project_resource_summary, tfidf_w2v_val_title, tfidf_w2v_val_essays))\n",
        "val_set_4y = val_df['project_is_approved'].to_numpy()\n",
        "\n",
        "test_set_4x = sparse.hstack((test_df_teacher_prefix, test_df_school_state, test_df_project_grade_category, test_df_clean_categories, test_df_clean_subcategories, test_df_price, test_df_quantity, test_df_pposts, test_df_project_resource_summary, tfidf_w2v_test_title, tfidf_w2v_test_essays))\n",
        "test_set_4y = test_df['project_is_approved'].to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bab51b6a-ef5c-4948-bb25-e6eee36f474d",
        "id": "-iye9RKobIgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_set_4x.shape)\n",
        "print(val_set_4x.shape)\n",
        "print(test_set_4x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 5803)\n",
            "(5000, 5803)\n",
            "(10000, 5803)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVE0Qe9whosZ",
        "colab_type": "code",
        "outputId": "706862b0-14e5-4081-9cf0-266db9c8a719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(type(train_set_1x))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'scipy.sparse.coo.coo_matrix'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqn5tN6IHVTg",
        "colab_type": "text"
      },
      "source": [
        "## 3. Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8khckdcMKft",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 PCA for dimensionality reduction on the train data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Qb7nyshpGUK",
        "colab_type": "text"
      },
      "source": [
        "As KNN is inefficient for data with large dimensionality, we reduce the dimensionality by using PCA such that 98% of the variance is explained by the new coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hlriuvmFTy5i",
        "colab": {}
      },
      "source": [
        "from sklearn import decomposition\n",
        "pca = decomposition.PCA(0.98)\n",
        "\n",
        "pca_1 = pca.fit(train_set_1x.todense())\n",
        "\n",
        "train_data_1x = pca_1.transform(train_set_1x.todense())\n",
        "val_data_1x = pca_1.transform(val_set_1x.todense())\n",
        "test_data_1x = pca_1.transform(test_set_1x.todense())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C7CjGvbqT1jm",
        "outputId": "5ed9aea7-70c3-4aba-b8dd-dd1dd7bc498b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_data_1x.shape)\n",
        "print(val_data_1x.shape)\n",
        "print(test_data_1x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 1001)\n",
            "(5000, 1001)\n",
            "(10000, 1001)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sr9I2bhDT5k9",
        "colab": {}
      },
      "source": [
        "pca_2 = pca.fit(train_set_2x.todense())\n",
        "\n",
        "train_data_2x = pca_2.transform(train_set_2x.todense())\n",
        "val_data_2x = pca_2.transform(val_set_2x.todense())\n",
        "test_data_2x = pca_2.transform(test_set_2x.todense())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KzM27SuIT5lK",
        "outputId": "b6d11ce5-1533-4d08-b343-814b91a56576",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_data_2x.shape)\n",
        "print(val_data_2x.shape)\n",
        "print(test_data_2x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 2355)\n",
            "(5000, 2355)\n",
            "(10000, 2355)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-oU_JerA8y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_3 = pca.fit(train_set_3x.todense())\n",
        "\n",
        "train_data_3x = pca_3.transform(train_set_3x.todense())\n",
        "val_data_3x = pca_3.transform(val_set_3x.todense())\n",
        "test_data_3x = pca_3.transform(test_set_3x.todense())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KByhVYsBGQL",
        "colab_type": "code",
        "outputId": "c90d8458-dffb-43c8-b3d2-ae1d217b8194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_data_3x.shape)\n",
        "print(val_data_3x.shape)\n",
        "print(test_data_3x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 1052)\n",
            "(5000, 1052)\n",
            "(10000, 1052)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl_tlIJOerkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pca_4 = pca.fit(train_set_4x.todense())\n",
        "\n",
        "train_data_4x = pca_4.transform(train_set_4x.todense())\n",
        "val_data_4x = pca_4.transform(val_set_4x.todense())\n",
        "test_data_4x = pca_4.transform(test_set_4x.todense())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-IeoYJChZOd",
        "colab_type": "code",
        "outputId": "ccf3a1c0-1ed4-4710-df97-d6d728654847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(train_data_4x.shape)\n",
        "print(val_data_4x.shape)\n",
        "print(test_data_4x.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(35000, 724)\n",
            "(5000, 724)\n",
            "(10000, 724)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seDkQPjIM4y8",
        "colab_type": "text"
      },
      "source": [
        "## 4. Applying K-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZlV78QrCIuX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_predict(clf, data):\n",
        "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
        "    # not the predicted outputs\n",
        "\n",
        "    y_data_pred = []\n",
        "    tr_loop = data.shape[0] - data.shape[0]%1000\n",
        "    # consider you X_tr shape is 49041, then your tr_loop will be 49041 - 49041%1000 = 49000\n",
        "    # in this for loop we will iterate unti the last 1000 multiplier\n",
        "    for i in range(0, tr_loop, 1000):\n",
        "        y_data_pred.extend(clf.predict_proba(data[i:i+1000])[:,1])\n",
        "    # we will be predicting for the last data points\n",
        "    if data.shape[0]%1000 !=0:\n",
        "        y_data_pred.extend(clf.predict_proba(data[tr_loop:])[:,1])\n",
        "    \n",
        "    return y_data_pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGt4579JNJZP",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Simple gridsearch cross-validation for hyperparameter tuning and selection of K (Plot AUC for each k)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZjLbaim9rxc",
        "colab_type": "code",
        "outputId": "fa3be79e-73b2-415f-ccee-9288a3763558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "'''\n",
        "val_auc = []\n",
        "K = [1275, 1375, 1475, 1575, 1675, 1775, 1875, 1975, 2075, 2175, 2275]\n",
        "\n",
        "for i in tqdm(K):\n",
        "    neigh = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\n",
        "    \n",
        "    neigh.fit(train_data_1x, train_set_1y)\n",
        "\n",
        "    y_val_pred = batch_predict(neigh, val_data_1x)\n",
        "\n",
        "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
        "    # not the predicted outputs\n",
        "    auc_i = roc_auc_score(val_set_1y, y_val_pred)\n",
        "    print(auc_i)\n",
        "    val_auc.append(auc_i)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.plot(K, val_auc, label='VAL AUC')\n",
        "\n",
        "#plt.scatter(K, train_auc, label='Train AUC points')\n",
        "plt.scatter(K, val_auc, label='CV AUC points')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"K: hyperparameter\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.title(\"AUC PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nval_auc = []\\nK = [1275, 1375, 1475, 1575, 1675, 1775, 1875, 1975, 2075, 2175, 2275]\\n\\nfor i in tqdm(K):\\n    neigh = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\\n    \\n    neigh.fit(train_data_1x, train_set_1y)\\n\\n    y_val_pred = batch_predict(neigh, val_data_1x)\\n\\n    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\\n    # not the predicted outputs\\n    auc_i = roc_auc_score(val_set_1y, y_val_pred)\\n    print(auc_i)\\n    val_auc.append(auc_i)\\n\\nplt.figure(figsize=(15,15))\\nplt.plot(K, val_auc, label=\\'VAL AUC\\')\\n\\n#plt.scatter(K, train_auc, label=\\'Train AUC points\\')\\nplt.scatter(K, val_auc, label=\\'CV AUC points\\')\\n\\nplt.legend()\\nplt.xlabel(\"K: hyperparameter\")\\nplt.ylabel(\"AUC\")\\nplt.title(\"AUC PLOTS\")\\nplt.grid()\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz9LQb0uHIXw",
        "colab_type": "text"
      },
      "source": [
        "We observe that K=1075 gives the highest AUC on validation data. **Thus we set K=1075 for SET_1 data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNDdAjX8FGlg",
        "colab_type": "code",
        "outputId": "9a938e13-2a4c-4300-b326-883dfcea4767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "val_auc = []\n",
        "K = [2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000]\n",
        "\n",
        "for i in tqdm(K):\n",
        "    neigh = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\n",
        "    \n",
        "    neigh.fit(train_data_2x, train_set_2y)\n",
        "\n",
        "    y_val_pred = batch_predict(neigh, val_data_2x)\n",
        "\n",
        "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
        "    # not the predicted outputs\n",
        "    auc_i = roc_auc_score(val_set_2y, y_val_pred)\n",
        "    print(auc_i)\n",
        "    val_auc.append(auc_i)\n",
        "\n",
        "plt.plot(K, val_auc, label='VAL AUC')\n",
        "\n",
        "#plt.scatter(K, train_auc, label='Train AUC points')\n",
        "plt.scatter(K, val_auc, label='CV AUC points')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"K: hyperparameter\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.title(\"AUC PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
            " 10%|█         | 1/10 [05:39<50:55, 339.53s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6200156851707888\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 20%|██        | 2/10 [11:21<45:22, 340.27s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6187320416780954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 30%|███       | 3/10 [17:04<39:47, 341.01s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6182446432090651\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 40%|████      | 4/10 [22:47<34:10, 341.74s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6172524113848561\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|█████     | 5/10 [28:34<28:36, 343.25s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6159170859082221\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 60%|██████    | 6/10 [34:23<22:59, 344.86s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6161983791159952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 70%|███████   | 7/10 [40:11<17:17, 345.93s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6160618577307063\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 8/10 [46:00<11:33, 346.72s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6173621577664168\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 90%|█████████ | 9/10 [51:48<05:47, 347.30s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6171266311347838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 10/10 [57:36<00:00, 347.40s/it]\u001b[A\n",
            "\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.6156843613118631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bv_DAedxF2_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "val_auc = []\n",
        "K = [650, 675, 700, 725, 750, 775, 800, 825, 850, 875, 900, 925, 950, 975, 1000, 1025, 1050, 1075, 1100, 1125, 1150, 1175, 1200, 1225, 1250, 1275, 1300, 1325, 1350, 1375, 1400, 1425, 1450, 1475, 1500, 1525, 1575, 1600, 1625, 1650, 1675, 1700, 1725, 1750]\n",
        "\n",
        "for i in tqdm(K):\n",
        "    neigh = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\n",
        "    \n",
        "    neigh.fit(train_data_3x, train_set_3y)\n",
        "\n",
        "    y_val_pred = batch_predict(neigh, val_data_3x)\n",
        "\n",
        "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
        "    # not the predicted outputs\n",
        "    auc_i = roc_auc_score(val_set_3y, y_val_pred)\n",
        "    print(auc_i)\n",
        "    val_auc.append(auc_i)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.plot(K, val_auc, label='VAL AUC')\n",
        "\n",
        "#plt.scatter(K, train_auc, label='Train AUC points')\n",
        "plt.scatter(K, val_auc, label='CV AUC points')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"K: hyperparameter\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.title(\"AUC PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f35rwRO-F4YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "val_auc = []\n",
        "K = [650, 675, 700, 725, 750, 775, 800, 825, 850, 875, 900, 925, 950, 975, 1000, 1025, 1050, 1075, 1100, 1125, 1150, 1175, 1200, 1225, 1250, 1275, 1300, 1325, 1350, 1375, 1400, 1425, 1450, 1475, 1500, 1525, 1575, 1600, 1625, 1650, 1675, 1700, 1725, 1750]\n",
        "\n",
        "for i in tqdm(K):\n",
        "    neigh = KNeighborsClassifier(n_neighbors=i, n_jobs=-1)\n",
        "    \n",
        "    neigh.fit(train_data_4x, train_set_4y)\n",
        "\n",
        "    y_val_pred = batch_predict(neigh, val_data_4x)\n",
        "\n",
        "    # roc_auc_score(y_true, y_score) the 2nd parameter should be probability estimates of the positive class\n",
        "    # not the predicted outputs\n",
        "    auc_i = roc_auc_score(val_set_4y, y_val_pred)\n",
        "    print(auc_i)\n",
        "    val_auc.append(auc_i)\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.plot(K, val_auc, label='VAL AUC')\n",
        "\n",
        "#plt.scatter(K, train_auc, label='Train AUC points')\n",
        "plt.scatter(K, val_auc, label='CV AUC points')\n",
        "\n",
        "plt.legend()\n",
        "plt.xlabel(\"K: hyperparameter\")\n",
        "plt.ylabel(\"AUC\")\n",
        "plt.title(\"AUC PLOTS\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aq89j4kNQ8S",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Apply KNN to all four datsets (Use lesser # of samples for W2V models) [GET 4 KNN MODELS]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkw2LAfLOc1g",
        "colab_type": "text"
      },
      "source": [
        "## 5. Test Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEgoRiwwOysO",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 Predict in batches on test data (Prediction in small batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4VFcieJO63d",
        "colab_type": "text"
      },
      "source": [
        "### 5.2 Plot ROC and confusion matrix for all four encodings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa52b1XnN3Qp",
        "colab_type": "text"
      },
      "source": [
        "## 6. Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ss5EVVUHOQUE",
        "colab_type": "text"
      },
      "source": [
        "### 5.1 Select top 200 features (Forward Selection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXwg2WyfOWn7",
        "colab_type": "text"
      },
      "source": [
        "## 7. Summary table "
      ]
    }
  ]
}